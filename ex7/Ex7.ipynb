{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>K-means Clustering and Principal Component Analysis</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first half of this exercise, you will be using K-means clustering algorithm and apply it to compress an image. In the next half of the exercise, you will be using component analysis to find a low-dimensional representation of face images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import linalg\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing K-Means on an example 2D Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Example Dataset which will help gain an intuition of how the K-means algorithm works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'X'])\n",
      "(300, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4a9a5639b549dda9fe33947f825422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = scipy.io.loadmat('ex7data2.mat')\n",
    "print(data.keys())\n",
    "X = data['X']\n",
    "print(X.shape)\n",
    "fig_data2 = plt.figure()\n",
    "ax_data2 = fig_data2.add_subplot(111) \n",
    "ax_data2 = sns.scatterplot(x=X.T[0], y=X.T[1])\n",
    "ax_data2.set(xlabel='Example data 2')\n",
    "fig_data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate closest centroids using Eucledian distance\n",
    "def findClosestCentroids(X, initial_centroids):\n",
    "    dist_arr = cdist(X, initial_centroids)\n",
    "    return (np.argmin(dist_arr, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update cluster centroid to the mean of all points in the cluster\n",
    "def updateCentroid(X, closest_centroids, K):\n",
    "    # Array to hold updated centroids\n",
    "    updated_centroids = np.empty((0,X.shape[1]))\n",
    "    for i in range(K):\n",
    "        X_sub = X[closest_centroids == i]\n",
    "        # Drop any centroids that don't have any points\n",
    "        if(X_sub.size > 0):\n",
    "            avg = np.mean(X_sub, axis=0).reshape(1, X.shape[1])\n",
    "            updated_centroids = np.append(updated_centroids, avg, axis=0)\n",
    "    return updated_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run K-Means Clustering\n",
    "def runkmeans(X, K, max_iter, initial_centroids):\n",
    "    # Array to hold list of centroids used to visualize in plot\n",
    "    cx, cy = initial_centroids.shape[0], initial_centroids.shape[1]\n",
    "    centroid_list = np.empty((0, cx, cy), int)\n",
    "    centroid_list = np.append(centroid_list, initial_centroids.reshape(1, cx, cy), axis=0)\n",
    "    for i in range(max_iter):\n",
    "        # Cluster Assignment by finding closest centroids\n",
    "        closest_centroids_idx = findClosestCentroids(X, initial_centroids)\n",
    "        # Update centroid\n",
    "        updated_centroids = updateCentroid(X, closest_centroids_idx, K)\n",
    "        centroid_list = np.append(centroid_list, updated_centroids.reshape(1, cx, cy), axis=0)\n",
    "        initial_centroids = updated_centroids\n",
    "    return (closest_centroids_idx, updated_centroids, centroid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097c1cbf48bc4bdfbd1537d833b5e1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run K-Means on sample 2D dataset\n",
    "K = 3\n",
    "max_iter = 10\n",
    "initial_centroids = np.array([[3, 3], [6, 2], [8, 5]])\n",
    "(closest_centroids_idx, updated_centroids, centroid_list) = runkmeans(X, K, max_iter, initial_centroids)\n",
    "\n",
    "fig_data22 = plt.figure()\n",
    "ax_data22 = fig_data22.add_subplot(111) \n",
    "ax_data22 = sns.scatterplot(x=X.T[0], y=X.T[1], hue=closest_centroids_idx)\n",
    "for i in range(K):\n",
    "    #ax_data22 = sns.lineplot(x=centroid_list[:,i,0], y=centroid_list[:,i,1], marker='x')\n",
    "    ax_data22.plot(centroid_list[:,i,0], centroid_list[:,i,1], marker='x')\n",
    "ax_data22.set(xlabel='Example data 2')\n",
    "ax_data22.get_legend().remove()\n",
    "title = \"K-Mean Clustering K = {}\".format(K)\n",
    "fig_data22.suptitle(title, fontsize=16)\n",
    "fig_data22.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random initialization of centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initRandomCentroid(X, K):\n",
    "    ind = np.random.randint(X.shape[0], size=K)\n",
    "    return X[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image compressions with K-Means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In normal image, each pixel is represented by three 8-bit unsigned int (total 24 bits) for Red, Green and Blue intensity values. One image contains 1000s of colors.\n",
    "In this compression, we are going to reduce to only 16 colors (represented by 4 bits) and each pixels will store only the index of the color.\n",
    "To achieve this using K-Means, run K-Means for 16 clusters to get the 16 colors that best represent the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'A'])\n",
      "(128, 128, 3) 6 255\n"
     ]
    }
   ],
   "source": [
    "# Reading image using .mat file\n",
    "imgmat = scipy.io.loadmat('bird_small.mat')\n",
    "print(imgmat.keys())\n",
    "img1 = imgmat['A']\n",
    "print(img1.shape, np.min(img1), np.max(img1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) 0.023529412 1.0\n"
     ]
    }
   ],
   "source": [
    "# Reading image file directly\n",
    "img2 = mpimg.imread('bird_small.png')\n",
    "print(img2.shape, np.min(img2), np.max(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9d28b3469a4771bd81510a2c4016f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run K-Means on image data\n",
    "img = img2\n",
    "#img = img1/255 - Normalize the image to scale all points 0 - 1\n",
    "imgX = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "\n",
    "K = 16\n",
    "max_iter = 10\n",
    "\n",
    "# Calculate initial centroid randomly\n",
    "initial_centroids = initRandomCentroid(imgX, K)\n",
    "\n",
    "# Run K-Means to calculate 16 cluster and its centroids\n",
    "(closest_centroids_idx, updated_centroids, centroid_list) = runkmeans(imgX, K, max_iter, initial_centroids)\n",
    "# Find closest cluster members\n",
    "closest_centroids_idx = findClosestCentroids(imgX, updated_centroids)\n",
    "\n",
    "# With 'K' Cluster indexes, we can replace each pixel in the image\n",
    "# with the the corresponding cluster centroid to get compressed version\n",
    "imgC = updated_centroids[closest_centroids_idx,:].reshape(img.shape[0],img.shape[1],3)\n",
    "\n",
    "# View original and compressed side by side\n",
    "fig_data1 = plt.figure()\n",
    "ax_data11 = fig_data1.add_subplot(121) \n",
    "ax_data11.imshow(img)\n",
    "ax_data11.set_title(\"Original\")\n",
    "ax_data12 = fig_data1.add_subplot(122) \n",
    "ax_data12.imshow(imgC)\n",
    "title = \"Compressed with {} colors\".format(K)\n",
    "ax_data12.set_title(title)\n",
    "fig_data1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use principal component analysis (PCA) to perform dimensionality reduction. First experiment with an example 2D dataset to get intuition on how PCA works, and then use it on a bigger dataset of 5000 face image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'X'])\n",
      "(50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reading example dataset\n",
    "pcadata = scipy.io.loadmat('ex7data1.mat')\n",
    "print(pcadata.keys())\n",
    "pcaX = pcadata['X']\n",
    "print(pcaX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot two charts\n",
    "#   1. Original data and its principal components\n",
    "#   2. Normalized data and and projected data, and connect these points\n",
    "def plotPCA(X, X_scaled, X_approx, eigenvectors, eigenvalues, num_comp, method):\n",
    "   # Get eigen vector plotting points\n",
    "    center = np.mean(X, axis=0).reshape(1,2)\n",
    "    vector_cood = np.vstack((center, center+(eigenvectors*eigenvalues.reshape(2,1)*1.5)))\n",
    "    \n",
    "    fig_pcadata1 = plt.figure(figsize=(10, 6))\n",
    "    ax_pcadata1 = fig_pcadata1.add_subplot(121)\n",
    "    # Plot Original data\n",
    "    ax_pcadata1 = sns.scatterplot(x=X.T[0], y=X.T[1], color='blue')\n",
    "    # Plot eigen vector\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        ax_pcadata1.plot(vector_cood[[0,i+1],0], vector_cood[[0,i+1],1], color='black', marker='x')\n",
    "    title = \"Original data and its principal components\"\n",
    "    ax_pcadata1.set_title(title, fontsize=8)\n",
    "    \n",
    "    ax_pcadata2 = fig_pcadata1.add_subplot(122)\n",
    "    # Plot normalized data\n",
    "    ax_pcadata2 = sns.scatterplot(x=X_scaled.T[0], y=X_scaled.T[1], color='blue')\n",
    "    # Plot Approximated data\n",
    "    ax_pcadata2 = sns.scatterplot(x=X_approx.T[0], y=X_approx.T[1], color='red')\n",
    "    # Draw lines connecting the projected points to the original points\n",
    "    lines = np.hstack\n",
    "    for i in range(X_scaled.shape[0]):\n",
    "        ax_pcadata2.plot([X_scaled[i][0], X_approx[i][0]], [X_scaled[i][1], X_approx[i][1]], 'k--', linewidth=1)\n",
    "    title = \"Normalized data and and projected data after {}\".format(method)\n",
    "    ax_pcadata2.set_title(title, fontsize=8)\n",
    "    \n",
    "    fig_pcadata1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projected data onto its principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We project the normalized data onto its 'K' principal components (eigen vectors - U).\n",
    "$$ U\\_reduce = U(:K, :) $$\n",
    "$$ X\\_reduce = U\\_reduce.X^T$$\n",
    "$$U - n x n, U\\_reduce - K x n, X - m x n, X\\_reduce - K x m $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectData(X_scaled, eigenvectors, num_comp):\n",
    "    U_reduce = eigenvectors[:num_comp,:]\n",
    "    X_reduce = U_reduce.dot(X_scaled.T)\n",
    "    return X_reduce.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstructing an approximation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reconstruct an approximate version of normalized data onto its 'K' principal components (eigen vectors - U).\n",
    "$$ U\\_reduce = U(:K, :) $$\n",
    "$$ X\\_approx = X\\_reduce^T.U\\_reduce$$\n",
    "$$ U\\_reduce - K x n, X\\_reduce - K x m, X\\_approx - m x n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverData(X_reduce, eigenvectors, num_comp):\n",
    "    U_reduce = eigenvectors[:num_comp,:]\n",
    "    X_approx = X_reduce.dot(U_reduce)\n",
    "    return X_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement PCA using scikit-learn and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA using scikit-learn library\n",
    "def runPCA(X, X_scaled, num_comp, print_comp, plot):\n",
    "    print(\"PCA using scikit-learn\")\n",
    "    num_dim = X.shape[1]\n",
    "    \n",
    "    # Init PCA with desired number of components\n",
    "    #pca = PCA(n_components=num_comp)\n",
    "    pca = PCA()\n",
    "    \n",
    "    # Reduce dimension\n",
    "    principalComponents = pca.fit_transform(X_scaled)\n",
    "   \n",
    "    # Print Eigen vector/values and variance explained by different components\n",
    "    eigenvectors = pca.components_\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    expvariances = pca.explained_variance_ratio_\n",
    "    if(print_comp):\n",
    "        for id, (expvariance, eigenvector, eigenvalue) in enumerate(zip(expvariances, eigenvectors, eigenvalues)):\n",
    "            print(\"Component {} - Explained Variance {}, Eigenvector {}, Eigenvalue {}\".format(id, expvariance, eigenvector, eigenvalue))\n",
    "    \n",
    "    # Get projected and approximate recovered data\n",
    "    X_reduce = projectData(X_scaled, eigenvectors, num_comp)\n",
    "    X_approx = recoverData(X_reduce, eigenvectors, num_comp)\n",
    "    \n",
    "    # Plot the original data and reduced data\n",
    "    if(plot and num_dim == 2 and num_comp == 1):\n",
    "        plotPCA(X, X_scaled, X_approx, eigenvectors, eigenvalues, num_comp, \"PCA\")\n",
    "        \n",
    "    return (X_reduce, X_approx, eigenvectors, eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA using covariance matrix and its singular value decomposition\n",
    "def runSVD(X, X_scaled, num_comp, print_comp, plot):\n",
    "    print(\"PCA using covariance matrix and its singular value decomposition\")\n",
    "    num_dim = X.shape[1]\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    cvm = np.cov(X_scaled.T)\n",
    "    \n",
    "    # Run singular value decomposition\n",
    "    (U, S, V) = linalg.svd(cvm)\n",
    "    if(print_comp):\n",
    "        for id, (eigenvector, eigenvalue) in enumerate(zip(U, S)):\n",
    "            print(\"Component {} - Eigenvector {}, Eigenvalue {}\".format(id, eigenvector, eigenvalue))\n",
    "    \n",
    "    # Get projected and approximate recovered data\n",
    "    X_reduce = projectData(X_scaled, U, num_comp)\n",
    "    X_approx = recoverData(X_reduce, U, num_comp)\n",
    "    \n",
    "    # Plot the original data and reduced data\n",
    "    if(plot and num_dim == 2 and num_comp == 1):\n",
    "        plotPCA(X, X_scaled, X_approx, U, S, num_comp, \"SVD\")\n",
    "        \n",
    "    return (X_reduce, X_approx, U, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA using scikit-learn\n",
      "Component 0 - Explained Variance 0.8677651881696649, Eigenvector [-0.70710678 -0.70710678], Eigenvalue 1.770949363611561\n",
      "Component 1 - Explained Variance 0.1322348118303352, Eigenvector [-0.70710678  0.70710678], Eigenvalue 0.26986696291905143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fd0518d9d9461db9d00019e92a1487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA using covariance matrix and its singular value decomposition\n",
      "Component 0 - Eigenvector [-0.70710678 -0.70710678], Eigenvalue 1.7709493636115605\n",
      "Component 1 - Eigenvector [-0.70710678  0.70710678], Eigenvalue 0.26986696291905093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1526066b0e42af9a6dda0c3b6b6089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run both PCA versions on the example dataset\n",
    "num_comp = 1\n",
    "# Normalize the data\n",
    "pcaX_scaled = preprocessing.scale(pcaX)\n",
    "(pcaX_reduce,  pcaX_approx,  pcaX_eigenvectors,  pcaX_eigenvalues)  = runPCA(pcaX, pcaX_scaled, num_comp, 1, 1)\n",
    "(pcaX_reduce2, pcaX_approx2, pcaX_eigenvectors2, pcaX_eigenvalues2) = runSVD(pcaX, pcaX_scaled, num_comp, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Image Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA on face images to see how it can be used in practice for dimension reduction. The dataset has 5000 images each of size 32 x 32 (1024) pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'X'])\n",
      "(5000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Reading face image dataset\n",
    "facedata = scipy.io.loadmat('ex7faces.mat')\n",
    "print(facedata.keys())\n",
    "faceX = facedata['X']\n",
    "print(faceX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDisplayImage(X):\n",
    "    numpixels1d = X.shape[1]\n",
    "    numpixels2d = int(np.sqrt(numpixels1d))\n",
    "\n",
    "    num_img = X.shape[0]\n",
    "    rows = cols = int(np.sqrt(num_img))\n",
    "    \n",
    "    pad = 1\n",
    "    patch = np.zeros((pad + (pad+numpixels2d)*rows, pad + (pad+numpixels2d)*cols))\n",
    "\n",
    "    for i in range(num_img):\n",
    "        row, col = i // rows, i % rows\n",
    "        img = X[i].reshape(numpixels2d, numpixels2d)\n",
    "        row_start, row_end = pad + row*(pad+numpixels2d),  (row+1)*(pad+numpixels2d)\n",
    "        col_start, col_end = pad + col*(pad+numpixels2d),  (col+1)*(pad+numpixels2d)\n",
    "        patch[row_start : row_end , col_start : col_end] = img.T\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA using scikit-learn\n"
     ]
    }
   ],
   "source": [
    "# Run PCA on face dataset\n",
    "num_comp = 100\n",
    "# Normalize the data\n",
    "faceX_scaled = preprocessing.scale(faceX)\n",
    "(faceX_reduce, faceX_approx, faceX_eigenvectors, faceX_eigenvalues) = runPCA(faceX, faceX_scaled, num_comp, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf02a3bb5fce443296b0a63cc8690b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLot eigen faces for first 36 principal components\n",
    "eigen_patch = getDisplayImage(faceX_eigenvectors[:36,:])\n",
    "\n",
    "fig_patchfacedata1 = plt.figure()\n",
    "\n",
    "ax_patchfacedata1 = fig_patchfacedata1.add_subplot(111)\n",
    "fig_patchfacedata1.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "ax_patchfacedata1.imshow(eigen_patch, cmap='gray', origin=\"upper\")\n",
    "ax_patchfacedata1.set_title(\"Eigen faces\")\n",
    "\n",
    "ax_patchfacedata1.axes.xaxis.set_visible(False)\n",
    "ax_patchfacedata1.axes.yaxis.set_visible(False)\n",
    "\n",
    "fig_patchfacedata1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2d3ea6770a4f419911602e9f9c2a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original and recovered images\n",
    "original_patch = getDisplayImage(faceX[:100,:])\n",
    "recovered_patch = getDisplayImage(faceX_approx[:100,:])\n",
    "\n",
    "fig_facedata1 = plt.figure()\n",
    "fig_facedata1.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "ax_facedata1 = fig_facedata1.add_subplot(121)\n",
    "ax_facedata1.imshow(original_patch, cmap='gray', origin=\"upper\")\n",
    "ax_facedata1.set_title(\"Original faces\")\n",
    "\n",
    "ax_facedata2 = fig_facedata1.add_subplot(122)\n",
    "ax_facedata2.imshow(recovered_patch, cmap='gray', origin=\"upper\")\n",
    "ax_facedata2.set_title(\"Recovered faces\")\n",
    "\n",
    "ax_facedata1.axes.xaxis.set_visible(False)\n",
    "ax_facedata1.axes.yaxis.set_visible(False)\n",
    "ax_facedata2.axes.xaxis.set_visible(False)\n",
    "ax_facedata2.axes.yaxis.set_visible(False)\n",
    "\n",
    "fig_facedata1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the final cluster assignments (obtained using K-Means) of pixels in the bird image in 3D space (RBG components). Then reduce it to 2D and visualize it in 2D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run K-Means on image data\n",
    "img = img2\n",
    "imgX = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "\n",
    "K = 16\n",
    "max_iter = 10\n",
    "\n",
    "# Calculate initial centroid randomly\n",
    "initial_centroids = initRandomCentroid(imgX, K)\n",
    "\n",
    "# Run K-Means to calculate 16 cluster and its centroids\n",
    "(closest_centroids_idx, updated_centroids, centroid_list) = runkmeans(imgX, K, max_iter, initial_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 random pixels\n",
    "num_samples = 1000\n",
    "indices = np.random.randint(0,imgX.shape[0], size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a colormap based on the number of clusters 'K'\n",
    "# and assign one color to each cluster index\n",
    "R = np.linspace(0,1,num=K)\n",
    "palette = plt.cm.hsv(R)\n",
    "colors = palette[closest_centroids_idx[indices], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4ab7573cdb480a9dc7f682dcec34e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot cluster assigmnents in 3D space\n",
    "fig_imgX = plt.figure()\n",
    "ax_imgX = fig_imgX.add_subplot(111, projection='3d')\n",
    "ax_imgX.scatter(imgX[indices,0], imgX[indices,1], imgX[indices,2], s=1, c=colors)\n",
    "ax_imgX.set_title(\"Visualize cluster membership for each pixel in 3D\")\n",
    "fig_imgX.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA using scikit-learn\n"
     ]
    }
   ],
   "source": [
    "# Run PCA to reduce to 2D\n",
    "(imgX_reduce, imgX_approx, imgX_eigenvectors, imgX_eigenvalues) = runPCA(imgX, imgX, 2, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255ddfd18f2c402784d8d567cf99dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot cluster assigmnents in 2D space\n",
    "fig_imgX_reduce = plt.figure()\n",
    "ax_imgX_reduce = fig_imgX_reduce.add_subplot(111)\n",
    "ax_imgX_reduce.scatter(imgX_reduce[indices,0], imgX_reduce[indices,1], s=1, c=colors)\n",
    "ax_imgX_reduce.set_title(\"Visualize cluster membership for each pixel in 2D\")\n",
    "fig_imgX_reduce.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
